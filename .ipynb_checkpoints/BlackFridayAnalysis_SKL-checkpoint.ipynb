{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "sns.set(style='ticks', color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a second take on the BlackFriday analysis focusing on using SKLearn for the predictions\n",
    "#MAIN QUESTION: Predict the purchase amount\n",
    "#first load the testing and training data set\n",
    "\n",
    "testBF = pd.read_csv(r'test.csv')\n",
    "trainBF = pd.read_csv(r'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.500680e+05</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>376430.000000</td>\n",
       "      <td>166821.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.003029e+06</td>\n",
       "      <td>8.076707</td>\n",
       "      <td>0.409653</td>\n",
       "      <td>5.404270</td>\n",
       "      <td>9.842329</td>\n",
       "      <td>12.668243</td>\n",
       "      <td>9263.968713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.727592e+03</td>\n",
       "      <td>6.522660</td>\n",
       "      <td>0.491770</td>\n",
       "      <td>3.936211</td>\n",
       "      <td>5.086590</td>\n",
       "      <td>4.125338</td>\n",
       "      <td>5023.065394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000001e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.001516e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5823.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.003077e+06</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>8047.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.004478e+06</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12054.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.006040e+06</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>23961.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User_ID     Occupation  Marital_Status  Product_Category_1  \\\n",
       "count  5.500680e+05  550068.000000   550068.000000       550068.000000   \n",
       "mean   1.003029e+06       8.076707        0.409653            5.404270   \n",
       "std    1.727592e+03       6.522660        0.491770            3.936211   \n",
       "min    1.000001e+06       0.000000        0.000000            1.000000   \n",
       "25%    1.001516e+06       2.000000        0.000000            1.000000   \n",
       "50%    1.003077e+06       7.000000        0.000000            5.000000   \n",
       "75%    1.004478e+06      14.000000        1.000000            8.000000   \n",
       "max    1.006040e+06      20.000000        1.000000           20.000000   \n",
       "\n",
       "       Product_Category_2  Product_Category_3       Purchase  \n",
       "count       376430.000000       166821.000000  550068.000000  \n",
       "mean             9.842329           12.668243    9263.968713  \n",
       "std              5.086590            4.125338    5023.065394  \n",
       "min              2.000000            3.000000      12.000000  \n",
       "25%              5.000000            9.000000    5823.000000  \n",
       "50%              9.000000           14.000000    8047.000000  \n",
       "75%             15.000000           16.000000   12054.000000  \n",
       "max             18.000000           18.000000   23961.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explore both data sets. Check dimensions, statistics, as well as null values\n",
    "trainBF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 12 columns):\n",
      "User_ID                       550068 non-null int64\n",
      "Product_ID                    550068 non-null object\n",
      "Gender                        550068 non-null object\n",
      "Age                           550068 non-null object\n",
      "Occupation                    550068 non-null int64\n",
      "City_Category                 550068 non-null object\n",
      "Stay_In_Current_City_Years    550068 non-null object\n",
      "Marital_Status                550068 non-null int64\n",
      "Product_Category_1            550068 non-null int64\n",
      "Product_Category_2            376430 non-null float64\n",
      "Product_Category_3            166821 non-null float64\n",
      "Purchase                      550068 non-null int64\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 50.4+ MB\n"
     ]
    }
   ],
   "source": [
    "trainBF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550068, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainBF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['User_ID',\n",
       " 'Product_ID',\n",
       " 'Gender',\n",
       " 'Age',\n",
       " 'Occupation',\n",
       " 'City_Category',\n",
       " 'Stay_In_Current_City_Years',\n",
       " 'Marital_Status',\n",
       " 'Product_Category_1',\n",
       " 'Product_Category_2',\n",
       " 'Product_Category_3',\n",
       " 'Purchase']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainBF.columns\n",
    "list(trainBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User_ID                       False\n",
       "Product_ID                    False\n",
       "Gender                        False\n",
       "Age                           False\n",
       "Occupation                    False\n",
       "City_Category                 False\n",
       "Stay_In_Current_City_Years    False\n",
       "Marital_Status                False\n",
       "Product_Category_1            False\n",
       "Product_Category_2             True\n",
       "Product_Category_3             True\n",
       "Purchase                      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for null values in training set\n",
    "trainBF.isnull().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User_ID                            0\n",
       "Product_ID                         0\n",
       "Gender                             0\n",
       "Age                                0\n",
       "Occupation                         0\n",
       "City_Category                      0\n",
       "Stay_In_Current_City_Years         0\n",
       "Marital_Status                     0\n",
       "Product_Category_1                 0\n",
       "Product_Category_2            173638\n",
       "Product_Category_3            383247\n",
       "Purchase                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainBF.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233599, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values in testing set, and chekc testing set shape\n",
    "testBF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['User_ID',\n",
       " 'Product_ID',\n",
       " 'Gender',\n",
       " 'Age',\n",
       " 'Occupation',\n",
       " 'City_Category',\n",
       " 'Stay_In_Current_City_Years',\n",
       " 'Marital_Status',\n",
       " 'Product_Category_1',\n",
       " 'Product_Category_2',\n",
       " 'Product_Category_3']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we'll notice that there is one less column in the testing set of data\n",
    "#testBF.columns\n",
    "list(testBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the testing data set does not have the \"Purchase\" column. \n",
    "#Therefore we will want to use the testing set as our X vlaues (dependant variable) is it contains all the things outsid the \"purchase\" column\n",
    "#the Training dataset will be our Y vairable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we want to handle the NAN or Null values in both data sets\n",
    "#I'm unsure what value to replace NAN or Null values, so let's just drop those values as to not uninentionally skew data by filling in inaapropriate values\n",
    "trainBF = trainBF.dropna()\n",
    "testBF = testBF.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User_ID                       0\n",
       "Product_ID                    0\n",
       "Gender                        0\n",
       "Age                           0\n",
       "Occupation                    0\n",
       "City_Category                 0\n",
       "Stay_In_Current_City_Years    0\n",
       "Marital_Status                0\n",
       "Product_Category_1            0\n",
       "Product_Category_2            0\n",
       "Product_Category_3            0\n",
       "Purchase                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm no more NAN or NUll values in data sets\n",
    "trainBF.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User_ID                       0\n",
       "Product_ID                    0\n",
       "Gender                        0\n",
       "Age                           0\n",
       "Occupation                    0\n",
       "City_Category                 0\n",
       "Stay_In_Current_City_Years    0\n",
       "Marital_Status                0\n",
       "Product_Category_1            0\n",
       "Product_Category_2            0\n",
       "Product_Category_3            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testBF.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No more missing values\n",
    "#Now we can begin training model\n",
    "#We may want to implement several models and see which produces most accurate results\n",
    "#Models we can use: Linear Regression, Decision Tree, Random Forest, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User_ID                         int64\n",
       "Product_ID                     object\n",
       "Gender                         object\n",
       "Age                            object\n",
       "Occupation                      int64\n",
       "City_Category                  object\n",
       "Stay_In_Current_City_Years     object\n",
       "Marital_Status                  int64\n",
       "Product_Category_1              int64\n",
       "Product_Category_2            float64\n",
       "Product_Category_3            float64\n",
       "Purchase                        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BEFORE we assign out x and y values, we will want to turn Categorical data into numerical.\n",
    "#this will help the model learn better\n",
    "#we can use the pandas to_numeric method, or hard code it\n",
    "#first find which columns are categorical. These will not have an int dtype.\n",
    "#they WILL be of dtype object\n",
    "trainBF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make copy of data sets\n",
    "trainCopy = trainBF.copy()\n",
    "testCopy = testBF.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will start with Decision tree\n",
    "#First thing to do is to define our x and y training and testing data\n",
    "#we need an x_train, x_test, y_train, y_test for our Decsion tree model and we will split up BOTH the train and test data sets\n",
    "#THE Y_TEST IS WHAT WE ARE LOOKING FOR! THIS IS THE UNKNOWN!\n",
    "#the x values will NOT have the \"Purchase\" column in it. VERY IMPORTANT!\n",
    "#we do this by using the pd.drop() fucntion.Remeber the you must specify the axis inwhich you want to split the data\n",
    "#axis = 0 means the index, axis = 1 measn the columns\n",
    "#Y will have the only the 'Purchase' column\n",
    "\n",
    "\n",
    "#X_test = testBF.drop(['Purchase'], axis=1)\n",
    "x_train = trainCopy.drop(['Purchase'], axis=1)\n",
    "#y_test = testBF['Purchase']\n",
    "y_train = trainCopy['Purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We may need to use the Label Encoder on the x_train data. Double check when are propper times to use Label encoder\n",
    "LE = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.apply(LE.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the product_ID, Gender, Age, City_Category, Stay_In_current_city_years columns are all categorical\n",
    "#now let's make them into numeric\n",
    "#Note: I think we only need to convert categorical into Numeric for the Training (X) values\n",
    "\n",
    "x_train['Product_Category_1'] = pd.to_numeric(x_train['Product_Category_1'])\n",
    "x_train['Product_Category_2'] = pd.to_numeric(x_train['Product_Category_2'])\n",
    "x_train['Product_Category_3'] = pd.to_numeric(x_train['Product_Category_3'])\n",
    "x_train['Gender'] = pd.to_numeric(x_train['Gender'])\n",
    "x_train['Age'] = pd.to_numeric(x_train['Age'])\n",
    "x_train['City_Category'] = pd.to_numeric(x_train['City_Category'])\n",
    "x_train['Stay_In_Current_City_Years'] = pd.to_numeric(x_train['Stay_In_Current_City_Years'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we can use the DecesionTreeRegrssor and fit our model with it\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "\n",
    "dtr_test = dtr.fit(x_train, y_train)\n",
    "dtr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear Regressoin\n",
    "LR = LinearRegression()\n",
    "LR_test = LR.fit(x_train, y_train)\n",
    "LR_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "GBR_test = GBR.fit(x_train, y_train)\n",
    "GBR_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\ensemble\\forest.py:244: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  warn(\"The default value of n_estimators will change from \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9182603569913936"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RandomForestRegresoion\n",
    "RFR =RandomForestRegressor()\n",
    "RFR_test =RFR.fit(x_train, y_train)\n",
    "RFR_test.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegression score: 1.0\n",
      "LinearRegression score: 0.19410146061613398\n",
      "GradientBoostingRegressor score:0.5453611103072871\n",
      "RandomForestRegressor score: 0.9182603569913936\n"
     ]
    }
   ],
   "source": [
    "#Since the model has been trained, we can now call the vairous regressors and see how they compare with one another\n",
    "print(f'DecisionTreeRegression score: {dtr_test.score(x_train, y_train)}')\n",
    "print(f'LinearRegression score: {LR_test.score(x_train, y_train)}')\n",
    "print(f'GradientBoostingRegressor score:{GBR_test.score(x_train, y_train)}')\n",
    "print(f'RandomForestRegressor score: {RFR_test.score(x_train, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-51ed421f1d8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Now we can use the trained model to predict!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_test_dtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtr_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
